{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a412d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from brian2tools import *\n",
    "from tools.functions import *\n",
    "from tools.srbm_reconstruction import *\n",
    "import matplotlib.pyplot as plt\n",
    "date = '2023-04-22'\n",
    "time = '20-45'\n",
    "path = \"output/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W, Wvh, Wch, mBv, mBh, b_c, b_v, b_h, mB = load_matrices(date, time, path)\n",
    "\n",
    "# load data that has been saved by main file \n",
    "length_stimuli = 200\n",
    "num_classes = 5\n",
    "\n",
    "train_test_sequence_data = load_data(len_stimuli = length_stimuli, \n",
    "                                    method=\"system\",\n",
    "                                    n_classes=num_classes,\n",
    "                                    n_obs = 1000, \n",
    "                                    var_prot=0.2,\n",
    "                                    repl_var=0.05)\n",
    "\n",
    "if length_stimuli != N_v or num_classes != n_classes:\n",
    "    print(\"The data does not fit the parameters in common_parameters.py. Please adjust the parameters in common_parameters.py to fit the data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparing the data\n",
    "sequence_data = get_data(n_samples=n_samples, min_p = .00001, max_p = .98, binary = True, seed=0, \n",
    "                           load_from_drive=False, data=train_test_sequence_data, num_classes = range(n_classes))\n",
    "Ids = np.column_stack([\n",
    "    create_single_Id(0, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 1.0) * 0,\n",
    "    create_single_Id(0, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 1.0) * 0 ,\n",
    "    create_single_Id(1, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 1.0),\n",
    "    create_single_Id(2, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 1.0, mult_data = 0.0) * 0,\n",
    "    create_single_Id(3, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 1.0) * 0,\n",
    "    create_single_Id(4, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 1.0 ) * 0\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def create_Id_pattern(n, data, N_v, N_c, n_c_unit, beta_parameter, on_off_ratio, seed = 0, data_mult = 1, class_mult = 0):\n",
    "    np.random.seed(seed)\n",
    "    Ids = [create_single_Id(0, data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 0.0)]\n",
    "    labels_out = []\n",
    "    labels = np.unique(data[1])\n",
    "    for i in range(n):\n",
    "        label = np.random.choice(labels, 1)[0]\n",
    "        Ids.append(create_single_Id(label, data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = class_mult, mult_data = data_mult))\n",
    "        labels_out.append(label)\n",
    "        for j in range(on_off_ratio):\n",
    "            Ids.append(create_single_Id(0, data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, \n",
    "                    beta_parameter = beta_parameter, \n",
    "                    mult_class = 0.0, mult_data = 0.0))\n",
    "            labels_out.append(label)\n",
    "    return (np.column_stack(Ids).T, labels_out)\n",
    "\n",
    "n_patterns = 5\n",
    "on_off_ratio = 2\n",
    "Ids, labels = create_Id_pattern(n_patterns, sequence_data, N_v = N_v, N_c = N_c, n_c_unit = n_c_unit, beta_parameter = beta_parameter, \n",
    "                        on_off_ratio = on_off_ratio, seed = 14, data_mult = 1, class_mult = 0)\n",
    "print(Ids.shape)\n",
    "print(labels[::3])\n",
    "\n",
    "timepoints, t_sim, time_points_dict = create_timepoints(Ids, init_delay, delay, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d797f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = main(W, b_v, b_c, b_h, t_sim = t_sim, Id = Ids, monitors = True)\n",
    "Mh, Mv, Mc= out['Mh'], out['Mv'], out['Mc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_rows = int(N_inputs/2)\n",
    "p1 = sequence_data[2][sequence_data[3] == 0][0:show_rows].reshape(show_rows, N_inputs)\n",
    "p2 = sequence_data[2][sequence_data[3] == 1][0:show_rows].reshape(show_rows, N_inputs)\n",
    "p3 = sequence_data[2][sequence_data[3] == 2][0:show_rows].reshape(show_rows, N_inputs)\n",
    "p4 = sequence_data[2][sequence_data[3] == 3][0:show_rows].reshape(show_rows, N_inputs)\n",
    "p5 = sequence_data[2][sequence_data[3] == 4][0:show_rows].reshape(show_rows, N_inputs)\n",
    "p6 = np.zeros((show_rows, N_inputs))\n",
    "\n",
    "plot_dat = [p1, p2, p3, p4, p5, p6]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(9,6), layout=\"compressed\")\n",
    "\n",
    "i = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(plot_dat[i], cmap='gray', interpolation=\"antialiased\")\n",
    "        col.axes.get_xaxis().set_ticks([])\n",
    "        col.axes.get_yaxis().set_ticks([])\n",
    "        i += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'antialiased', 'none', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36', 'hanning', \n",
    "# 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', \n",
    "# 'lanczos', 'blackman'\n",
    "label_ids = np.arange(1, n_patterns*on_off_ratio, on_off_ratio+1) # every nth label is taken as each id pattern is shown for n timepoints and not present for n more \n",
    "\n",
    "plot_id1=np.array(np.repeat(Ids[label_ids[0]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "plot_id2=np.array(np.repeat(Ids[label_ids[1]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "plot_id3=np.array(np.repeat(Ids[label_ids[2]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "plot_id4=np.array(np.repeat(Ids[label_ids[3]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "plot_id5=np.array(np.repeat(Ids[label_ids[4]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "plot_id6=np.array(np.repeat(Ids[label_ids[5]][0:N_inputs], show_rows)).reshape(N_inputs,show_rows).T\n",
    "\n",
    "plot_ids = [plot_id1, plot_id2, plot_id3, plot_id4, plot_id5, plot_id6]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(9,6), layout=\"compressed\")\n",
    "i = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(plot_ids[i], cmap='gray', interpolation=\"antialiased\")\n",
    "        col.axes.get_xaxis().set_ticks([])\n",
    "        col.axes.get_yaxis().set_ticks([])\n",
    "        col.set_title(labels[label_ids[i]])\n",
    "        i += 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359faec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_point_start_ids = np.arange(0, len(timepoints), (on_off_ratio+1) * 2) + 1\n",
    "time_point_end_ids = np.arange(0, len(timepoints), (on_off_ratio+1) * 2) + 3\n",
    "\n",
    "delay1 = 10, \n",
    "delay2 = delay1\n",
    "delay3 = delay1\n",
    "\n",
    "vist1 = np.repeat(np.array(spike_histogram(Mv,timepoints[time_point_start_ids[0]]+delay1*t_ref,timepoints[time_point_end_ids[0]])).T[1], show_rows).reshape(N_inputs,show_rows).T\n",
    "vist2 = np.repeat(np.array(spike_histogram(Mv,timepoints[time_point_start_ids[1]]+delay2*t_ref,timepoints[time_point_end_ids[1]])).T[1], show_rows).reshape(N_inputs,show_rows).T\n",
    "vist3 = np.repeat(np.array(spike_histogram(Mv,timepoints[time_point_start_ids[2]]+delay3*t_ref,timepoints[time_point_end_ids[2]])).T[1], show_rows).reshape(N_inputs,show_rows).T\n",
    "\n",
    "p1 = np.repeat(np.mean(sequence_data[2][sequence_data[3] == labels[label_ids[0]]][0:show_rows].reshape(show_rows, N_inputs), axis=0), show_rows).reshape(N_inputs, show_rows).T\n",
    "p2 = np.repeat(np.mean(sequence_data[2][sequence_data[3] == labels[label_ids[1]]][0:show_rows].reshape(show_rows, N_inputs), axis=0), show_rows).reshape(N_inputs, show_rows).T\n",
    "p3 = np.repeat(np.mean(sequence_data[2][sequence_data[3] == labels[label_ids[2]]][0:show_rows].reshape(show_rows, N_inputs), axis=0), show_rows).reshape(N_inputs, show_rows).T\n",
    "\n",
    "plt_list = [vist1, vist2, vist3, p1, p2, p3]\n",
    "titles = [\"Reconstruction 1\", \"Reconstruction 2\", \"Reconstruction 3\", \"Pattern 1\", \"Pattern 2\", \"Pattern 3\"]\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(9,6), layout=\"compressed\")\n",
    "i = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(plt_list[i], cmap='gray', interpolation=\"antialiased\")\n",
    "        col.axes.get_xaxis().set_ticks([])\n",
    "        col.axes.get_yaxis().set_ticks([])\n",
    "        col.set_title(titles[i])\n",
    "        i += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequency_classification(Mc, n_classes, n_c_unit, t_ref=t_ref, t_start=T1_s, t_end=T1_e*second, delay = 10)\n",
    "def hamming_distance(x, y):\n",
    "    return np.sum(np.abs(x - y))\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "def rmse(x, y):\n",
    "    return np.sqrt(np.mean((x - y)**2))\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.sum(x**2)) * np.sqrt(np.sum(y**2)))\n",
    "def to_binary(data, threshold = 0.5):\n",
    "    return np.array(data > threshold, dtype=np.int)\n",
    "def rescale(spike_histogram, new_max = 1, threshold = None):\n",
    "    if threshold is not None:\n",
    "        spike_histogram = to_binary(spike_histogram, np.max(spike_histogram) * threshold)\n",
    "    return spike_histogram * new_max / np.max(spike_histogram)\n",
    "def plot_output(spike_histogram, depth = 100):\n",
    "    length = len(spike_histogram)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.repeat(spike_histogram, depth).reshape(length, depth).T, cmap='gray')\n",
    "    plt.show()\n",
    "s_hist = np.array(spike_histogram(Mv,T3_s+delay1*t_ref,T3_e)).T[1]\n",
    "s_bin = rescale(s_hist, 1, threshold=0.3)\n",
    "\n",
    "orig_bin = to_binary(train_test_sequence_data[0][train_test_sequence_data[1] == 1][0], 0.5)\n",
    "\n",
    "\"\"\" plot_output(s_bin)\n",
    "plot_output(orig_bin)\n",
    "s_bin \"\"\"\n",
    "mean_0 = np.mean(sequence_data[2][sequence_data[3] == 0][0:show_rows].reshape(show_rows, N_inputs), axis=0)\n",
    "mean_1 = np.mean(sequence_data[2][sequence_data[3] == 1][0:show_rows].reshape(show_rows, N_inputs), axis=0)\n",
    "mean_2 = np.mean(sequence_data[2][sequence_data[3] == 2][0:show_rows].reshape(show_rows, N_inputs), axis=0)\n",
    "mean_3 = np.mean(sequence_data[2][sequence_data[3] == 3][0:show_rows].reshape(show_rows, N_inputs), axis=0)\n",
    "mean_4 = np.mean(sequence_data[2][sequence_data[3] == 4][0:show_rows].reshape(show_rows, N_inputs), axis=0)\n",
    "\n",
    "orig_bin_0 = to_binary(mean_0, 0.5)\n",
    "orig_bin_1 = to_binary(mean_1, 0.5)\n",
    "orig_bin_2 = to_binary(mean_2, 0.5)\n",
    "orig_bin_3 = to_binary(mean_3, 0.5)\n",
    "orig_bin_4 = to_binary(mean_4, 0.5)\n",
    "\n",
    "dist_01 = hamming_distance(orig_bin_0, orig_bin_1)\n",
    "dist_02 = hamming_distance(orig_bin_0, orig_bin_2)\n",
    "dist_03 = hamming_distance(orig_bin_0, orig_bin_3)\n",
    "dist_04 = hamming_distance(orig_bin_0, orig_bin_4)\n",
    "dist_12 = hamming_distance(orig_bin_1, orig_bin_2)\n",
    "dist_13 = hamming_distance(orig_bin_1, orig_bin_3)\n",
    "dist_14 = hamming_distance(orig_bin_1, orig_bin_4)\n",
    "dist_23 = hamming_distance(orig_bin_2, orig_bin_3)\n",
    "dist_24 = hamming_distance(orig_bin_2, orig_bin_4)\n",
    "dist_34 = hamming_distance(orig_bin_3, orig_bin_4)\n",
    "\n",
    "distances = [dist_01, dist_02, dist_03, dist_04, dist_12, dist_13, dist_14, dist_23, dist_24, dist_34]\n",
    "distances\n",
    "spike_hist_0_hidden = np.array(spike_histogram(Mh,time_points_dict[\"T7_s\"]+delay1*t_ref,time_points_dict[\"T7_e\"])).T[1]\n",
    "spike_hist_1_hidden = np.array(spike_histogram(Mh,time_points_dict[\"T10_s\"]+delay1*t_ref,time_points_dict[\"T10_e\"])).T[1]\n",
    "\n",
    "spike_hist_3_hidden = np.array(spike_histogram(Mh,time_points_dict[\"T1_s\"]+delay1*t_ref,time_points_dict[\"T1_e\"])).T[1]\n",
    "spike_hist_4_hidden = np.array(spike_histogram(Mh,time_points_dict[\"T4_s\"]+delay1*t_ref,time_points_dict[\"T4_e\"])).T[1]\n",
    "\n",
    "\n",
    "spike_hist_0_hidden_scaled = rescale(spike_hist_0_hidden, 1)\n",
    "spike_hist_1_hidden_scaled = rescale(spike_hist_1_hidden, 1)\n",
    "spike_hist_3_hidden_scaled = rescale(spike_hist_3_hidden, 1)\n",
    "spike_hist_4_hidden_scaled = rescale(spike_hist_4_hidden, 1)\n",
    "\n",
    "dist_hidden_01 = hamming_distance(spike_hist_0_hidden_scaled, spike_hist_1_hidden_scaled)\n",
    "#dist_hidden_02 = hamming_distance(spike_hist_0_hidden_scaled, spike_hist_2_hidden_scaled)\n",
    "dist_hidden_03 = hamming_distance(spike_hist_0_hidden_scaled, spike_hist_3_hidden_scaled)\n",
    "dist_hidden_04 = hamming_distance(spike_hist_0_hidden_scaled, spike_hist_4_hidden_scaled)\n",
    "#dist_hidden_12 = hamming_distance(spike_hist_1_hidden_scaled, spike_hist_2_hidden_scaled)\n",
    "dist_hidden_13 = hamming_distance(spike_hist_1_hidden_scaled, spike_hist_3_hidden_scaled)\n",
    "dist_hidden_14 = hamming_distance(spike_hist_1_hidden_scaled, spike_hist_4_hidden_scaled)\n",
    "#dist_hidden_23 = hamming_distance(spike_hist_2_hidden_scaled, spike_hist_3_hidden_scaled)\n",
    "#dist_hidden_24 = hamming_distance(spike_hist_2_hidden_scaled, spike_hist_4_hidden_scaled)\n",
    "dist_hidden_34 = hamming_distance(spike_hist_3_hidden_scaled, spike_hist_4_hidden_scaled)\n",
    "\n",
    "distances_hidden = [dist_hidden_01, dist_hidden_03, dist_hidden_04, dist_hidden_13, dist_hidden_14, dist_hidden_34]\n",
    "distances_hidden\n",
    "plot_output(spike_hist_0_hidden_scaled, depth=20)\n",
    "print(\"Hamming distance: \", hamming_distance(s_bin, orig_bin), sep=\"\")\n",
    "print(\"Euclidean distance: \", euclidean_distance(s_bin, orig_bin), sep=\"\")\n",
    "print(\"RMSE: \", rmse(s_bin, orig_bin), sep=\"\")\n",
    "print(\"Cosine similarity: \", cosine_similarity(s_bin, orig_bin), sep=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_raster(Mc.i, Mc.t, markersize=2, marker='|', color='k', mew=1)\n",
    "for i in range(n_classes):\n",
    "    axhline(-0.6+float(i)*4, color='k', linewidth=0.5)\n",
    "color_list = ['k', '#FFFFFF', \"r\"]\n",
    "col_cnt = 0\n",
    "for i in timepoints:\n",
    "    axvline(i/second*1000, color=color_list[col_cnt%len(color_list)], linewidth=0.5)\n",
    "    col_cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823708fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_raster(Mv.i, Mv.t, markersize=2,marker='|', color='k', mew=1)\n",
    "col_cnt = 0\n",
    "for i in timepoints:\n",
    "    axvline(i/second*1000, color=color_list[col_cnt%len(color_list)], linewidth=0.5)\n",
    "    col_cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ec5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_raster(Mh.i, Mh.t, markersize=2,marker='|', color='k', mew=1)\n",
    "col_cnt = 0\n",
    "for i in timepoints:\n",
    "    axvline(i/second*1000, color=color_list[col_cnt%len(color_list)], linewidth=0.5)\n",
    "    col_cnt += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
